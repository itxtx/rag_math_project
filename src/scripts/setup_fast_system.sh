#!/bin/bash
# scripts/setup_fast_system.sh

echo "ğŸš€ Setting up Fast RAG System (no new dependencies!)"
echo "=========================================="

# Create optimized directories
echo "ğŸ“ Creating optimized directory structure..."
mkdir -p data/embeddings/cache/
mkdir -p data/performance_logs/
mkdir -p src/retrieval/
mkdir -p src/data_ingestion/optimized/

echo "âœ… Directory structure created"

# Backup original files
echo "ğŸ’¾ Creating backups of original files..."
if [ -f "src/api/main_api.py" ]; then
    cp src/api/main_api.py src/api/main_api.py.backup
    echo "  âœ“ Backed up main_api.py"
fi

if [ -f "src/pipeline.py" ]; then
    cp src/pipeline.py src/pipeline.py.backup
    echo "  âœ“ Backed up pipeline.py"
fi

# Pre-compile Python files for faster imports
echo "ğŸ”§ Pre-compiling Python files..."
python -m compileall src/ --quiet

echo "ğŸ“Š Checking current system performance..."
python -c "
import time
start = time.time()
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
load_time = time.time() - start
print(f'  Model load time: {load_time:.2f}s')

start = time.time()
embedding = model.encode(['test query'])
embed_time = time.time() - start
print(f'  Embedding time: {embed_time:.3f}s')
"

echo ""
echo "âœ… Fast RAG System setup complete!"
echo ""
echo "ğŸ¯ Next steps:"
echo "  1. Process documents:    python -m src.fast_pipeline ingest"
echo "  2. Train GNN (optional): python -m src.fast_pipeline train-gnn"
echo "  3. Test performance:     python -m src.fast_pipeline test"
echo "  4. Start fast server:    python -m src.fast_pipeline serve"
echo ""
echo "ğŸ“ˆ Expected improvements:"
echo "  âš¡ 5-10x faster repeat queries (caching)"
echo "  âš¡ 2-3x faster embedding generation (batch processing)"
echo "  âš¡ 50% faster server startup (lazy loading)"
echo "  âš¡ Better concurrent performance (async operations)"